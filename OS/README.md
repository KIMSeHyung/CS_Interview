# Operating System

* [프로세스와 쓰레드의 차이](#프로세스와-쓰레드의-차이)
* [선점형 스케줄링과 비선점형 스케줄링](#선점형-스케줄링과-비선점형-스케줄링)
* [PCB와 프로세스 컨텍스트](#PCB와-프로세스-컨텍스트)
* [가상메모리](#가상메모리)
* [페이징과 세그먼테이션](#페이징과-세그먼테이션)
* [페이지 교체 알고리즘](#페이지-교체-알고리즘)
* [세마포어, 뮤텍스, 스핀락의 차이점](#세마포어-뮤텍스-스핀락-차이점)
* [스핀락을 사용하는 이유](#스핀락을-사용하는-이유)
* [데드락의 발생 조건](#데드락의-발생-조건)
* [C언어의 strtok 함수를 멀티쓰레드 환경에서 사용하면 안 되는 이유](#C언어의-strtok-함수를-멀티쓰레드-환경에서-사용하면-안-되는-이유)
* [IPC의 종류와 특징](#IPC-종류와-특징)
* [fork와 vfork의 차이점](#fork와-vfork의-차이점)
* [시나리오 문제](#시나리오-문제)
    * 프로세스A에서 파일A를 open하여 fd 3번을 할당받았다. (아래 문제들은 각각 독립적으로 동작한다고 가정한다. 오프셋 위치에 대한 이유도 함께 설명)
    * Q1. 그 후 쓰레드를 하나 생성하고, 쓰레드 리더 (쓰레드를 생성한 프로세스) 에서 fd3에 접근하여 파일 오프셋이 100으로 바뀌었다. 그 후 생성된 쓰레드에서 fd 3에 접근하면 오프셋 위치는?
    * Q2. 그 후 자식 프로세스를 하나 생성하고, 부모 프로세스에서 fd 3 에 접근하여 부모 프로세스의 fd 3에 대한 오프셋이 100으로 바뀌었다. 이 후 자식 프로세스에서 fd 3에 접근하면 오프셋의 위치는?
    * Q3. Q2와 같이 자식 프로세스를 하나 생성하고, 부모 프로세스와 자식 프로세스가 모두 파일 B에 대해 새로 open하여 fd 4를 할당받았다. 그리고 부모 프로세스가 fd 4에 접근해 오프셋이 100으로 바뀌었다. 그 후 자식 프로세스가 fd4에 접근할 때 오프셋 위치는?

---

## 프로세스와 쓰레드의 차이

* 공룡책 등에 소개되는 개념에 의하면 프로세스는 실행 혹은 실행 가능 상태에 있는 프로그램 인스턴스이고, 쓰레드는 프로세스 안에서 실행되는 흐름의 단위로 CPU 이용의 기본 단위이다.
* 프로세스의 메모리는 역할에 따라 크게 Code, Data, Heap, Stack 세그먼트로 구분된다.
    * Code 세그먼트는 프로그램 명령어를 구성하는 메모리 영역이다.
    * Data 세그먼트는 전역/정적 변수를 저장하는 영역이다.
        * 읽기 전용 데이터는 .rodata, 초기화 된 데이터는 .data, 초기화 되지 않은 데이터는 .bss 영역에 저장한다.
    * Heap 세그먼트는 동적 할당 시 사용한다.
    * Stack 세그먼트는 함수의 스택 프레임(지역 변수, 매개 변수, 리턴 값 등)을 구성할 때 사용한다.
* 이론적으로 프로세스는 각각 독립된 메모리 영역을 할당받아서, 한 프로세스는 다른 프로세스의 메모리에 접근할 수 없다. (가상메모리 개념과 연계됨)
* 이론적으로 쓰레드는 프로세스 내에서 레지스터와 Stack 세그먼트만 따로 할당받고, 그 외의 세그먼트는 공유한다.
* 실제 구현상(UNIX, Linux, MAC OS, Windows 등) 위의 내용은 일부 일치하지 않을 수 있다.
    * 예를 들어 Linux에서는 프로세스와 쓰레드를 모두 ```struct task_struct```로 표현한다. 리눅스 커널에서 새로운 프로세스나 쓰레드 생성의 실질적인 처리는 ```kernel_clone()```에서 이루어진다. (과거 ```_do_fork()``` 함수였다가 이름 변경됨) 해당 함수 내부에서는 ```copy_process()``` 함수를 호출하여 부모 프로세스의 여러 내용을 복사해주는데, 유저 스페이스로부터 전달받은 CLONE_FLAG에 따라 복사하는 내용이 달라진다. 그리고 유저 스페이스에서 호출하는 시스템콜에 따라 (프로세스 생성 시스템콜인지 쓰레드 생성 시스템콜인지 따라) 이 CLONE_FLAG가 달라지게 되어, 부모 프로세스로부터 복사받는 내용과 별개로 할당되는 내용 등의 범위가 달라지게 되는 것이다.
* 공룡책에서 소개되는 개념에 의하면 이론적으로 쓰레드가 CPU 이용의 기본 단위라고 하였는데, 실제로는 jail(FreeBSD)이나 cgroup(Linux) 등의 개념 도입에 따라 별도 스케줄링 유닛으로 대체되었다. 리눅스의 경우 ```struct sched_entity```가 스케줄링을 위한 기본 유닛이 되며, ```struct task_struct```는 멤버로 ```struct sched_entity``` 객체를 포함하게 된다.

## 선점형 스케줄링과 비선점형 스케줄링

* 선점형(Preemptive) 스케줄링 : 어떤 쓰레드가 CPU를 할당받아 실행 중에 있어도 다른 쓰레드가 실행 중인 쓰레드를 중지하고 CPU를 강제로 점유할 수 있는 스케줄링 방식이다. 빠른 응답시간을 요구하는 시분할 시스템에 적합하다.
    * 대표 알고리즘 : 라운드 로빈 스케줄링, 멀티레벨 큐 스케줄링
* 비선점(Non-preemptive) 스케줄링 : 어떤 쓰레드가 CPU를 할당 받으면 그 쓰레드가 종료되거나 IO가 발생하여 자발적으로 중지될 때까지 계속 실행하도록 보장하는 스케줄링 방식이다. 작업의 응답 시간을 예상할 수 있지만 처리율이 떨어질 수 있다. 주로 일괄 처리 시스템에 적합하다.
    * 대표 알고리즘 : FCFS(First Come First Served), SJF(Shortest Job First)
* 실제로 사용되는 스케줄링 알고리즘은 ULE(FreeBSD)와 CFS(Linux)가 있다.
    * CFS는 태스크들의 우선순위를 기반으로 상대적 실행시간인 vruntime을 계산하여, 시스템에 존재하는 모든 태스크의 vruntime이 비슷하게 맞춰지도록 스케줄링하는 선점형 스케줄러이다.
    * 실제로 시스템에는 하나의 스케줄러만 사용하는 것이 아니라, 태스크(프로세스/쓰레드)에 리얼타임 우선순위, 일반 우선순위 등을 구분하여 부여한 후 우선순위에 따라 서로 다른 스케줄러에서 처리할 수 있도록 구성되어 있다. 예를 들어 -100부터 -1까지는 RT 우선순위이고 0부터 39까지는 일반 우선순위여서 해당 우선순위에 따라 데드라인 스케줄러가 처리하거나 CFS 스케줄러가 처리하는 등의 방식이다.

## PCB와 프로세스 컨텍스트

* PCB(Process Control Block)은 프로세스 관리를 위한 메타데이터를 저장하고 있는 커널에서 관리하는 자료구조이다.
    * 이론적으로 다음과 같은 정보들을 포함한다.
        * PID
        * Process State : create, ready, running, waiting, terminated
        * Program Counter : 이 프로세스가 다음에 실행할 명령어의 주소
        * Process Context
        * 스케줄링 정보
        * 메모리 관리 정보
        * 기타 프로세스 정보
* 프로세스 컨텍스트 : CPU가 해당 프로세스를 실행하기 위한 프로세스의 데이터 모음이다.
    * 인터럽트가 발생했을 때, 인터럽트 핸들러를 수행한 후 원래 코드로 복귀하려면 프로세서의 상태를 저장하고 복원해야 한다. 프로세서는 레지스터를 기반으로 코드를 수행하므로 프로세서의 상태는 코드 수행에 관계된 레지스터의 집합이라고 할 수 있다. 이렇게 프로세서의 상태와 관계된 레지스터의 집합을 컨텍스트라고 한다.
    * 일반적으로 저장 및 복원하는 레지스터는 다음과 같다. (SS ~ IP는 프로세서가 처리하며, 커널의 핸들러는 그 외 부분을 처리한다.)
        * SS : 스택 영역을 가리키는 세그먼트 레지스터
        * SP : 현재 스택의 주소를 저장하는 포인터 레지스터
        * FLAGS : 상태 플래그를 저장하는 레지스터
        * CS : 코드 영역을 가리키는 세그먼트 레지스터
        * IP : 프로세서가 읽고 있는 현재 명령어의 위치를 가리키는 포인터 레지스터
        * BP : 스택의 데이터에 접근할 때 사용하는 포인터 레지스터
        * 범용 레지스터(AX ~ R15)
        * 세그먼트 셀렉터(DS ~ GS)
        * OS마다 처리하는 레지스터 종류들은 달라질 수 있으며, 어떤 레지스터를 처리하는지까지 숙지할 필요는 없다. (주로 스택이나 명령어에 대한 정보들을 담고있는 레지스터들과 범용 레지스터들을 저장한다고 알고있으면 된다.)
* 컨텍스트 스위칭 : 하나의 프로세스가 CPU를 사용 중인 상태에서 다른 프로세스가 CPU를 사용하도록 하기 위해, 이전 프로세스의 컨텍스트를 보관하고 새로운 프로세스의 컨텍스트를 적재하는 작업
    * 컨텍스트 스위칭을 자주할수록 컨텍스트 저장 및 적재 등에 의한 오버헤드가 생겨서 시스템 전체적인 성능이 저하한다. 반대로 컨텍스트 스위칭을 너무 적게 하면 원하는 작업에 대한 반응 속도가 늦어진다. 따라서 적절한 빈도의 컨텍스트 스위칭을 수행해야 한다.
* 실제 리눅스 커널에서 프로세스 및 쓰레드를 관리하기 위하여 사용하는 구조체는 ```struct task_struct```이며, 해당 구조체가 PCB의 역할을 수행한다.
    * ```struct task_struct```의 주요 멤버는 다음과 같다.
        * ```struct thread_info thread_info``` : 아키텍처별로(x86/arm 등) 구현되어 있으며 주로 프로세스 컨텍스트 관련 정보들을 저장한다.
        * ```struct mm_struct *mm``` : 프로세스가 관리하는 메모리 관련 정보를 가리킨다.
        * ```pid_t pid``` : 프로세스의 pid
        * ```int prio``` : 프로세스의 우선순위
        * 해당 구조체는 매우 거대한 구조체이므로 그 외에도 정말 많은 멤버들을 포함한다. 자세한 정의를 보고 싶으면 [링크](https://elixir.bootlin.com/linux/v5.14.11/source/include/linux/sched.h#L661)를 참고한다.

## 가상메모리

* 가상 메모리는 프로세스가 동작할 때 가상의 메모리 레이아웃 위에서 동작할 수 있게 하는 메모리 관리 기법이다.
* 이로 인하여 볼 수 있는 대표적인 효과들은 다음과 같다.
    * 프로세스에서 실제 하드웨어 메모리 레이아웃을 몰라도 프로그래밍을 할 수 있다.
    * 실제 주기억장치 크기보다 큰 메모리를 할당받을 수 있다.
    * 프로세스마다 서로 독립적인 공간을 할당받게 되어 서로 간섭하지 않게 할 수 있다.

## 페이징과 세그먼테이션

* 페이징과 세그먼테이션은 메모리를 분할하여 사용하는 메모리 관리 기법이다.
* 페이징 : 메모리를 일정한 크기의 페이지와 페이지 프레임으로 나눠서 관리한다. (고정 분할 기법)
    * 프레임 : 물리 메모리를 일정한 크기로 나눈 블록
    * 페이지 : 가상 메모리를 일정한 크기로 나눈 블록
    * 페이지와 프레임의 크기는 같으며, 일반적인 데스크탑에서 보통 4K의 크기를 갖는다.
    * 페이지가 프레임을 할당 받으면 메인 메모리에 위치하게 되며, 프레임을 할당 받지 못한 페이지들은 보조 기억장치에 저장된다.
* 세그먼테이션 : 프로세스의 메모리를 논리적인 내용을 기반으로 나눠서 배치 및 관리한다. (동적 분할 기법)
    * 세그먼테이션을 구현하기 위하여 세그먼트 셀렉터, 세그먼트 디스크립터, 세그먼트 테이블이 사용된다.
    * 세그먼트 셀렉터 : 세그먼트 디스크립터를 가리키는 레지스터
    * 세그먼트 디스크립터 : 세그먼트에 대한 정보를 가지고 있는 자료구조
    * 세그먼트 테이블 : 세그먼트 디스크립터를 모아둔 테이블
    * 선형 주소 접근 과정
        1. GDTR/LDTR 레지스터로 세그먼트 디스크립터의 주소를 구한다.
        2. 디스크립터 주소에 세그먼트 셀렉터의 주소 값을 더해(인덱스에 8을 곱하여 더함) 세그먼트 디스크립터의 주소를 구한다.
        3. 세그먼트 디스크립터에 있는 Base Address로 세그먼트의 시작 주소를 얻는다.
        4. 세그먼트 시작 주소에 선형 주소의 Offset을 더해 원하는 데이터 주소를 구한다.
* 페이징 기법을 사용하면 필요한 메모리보다 더 큰 양의 메모리를 할당해서 메모리 블록의 내부가 낭비되는 내부 단편화가 생긴다.
    * 예를 들어 1KB의 메모리를 필요로 하는 프로세스에게 4KB의 페이지를 할당하면 내부적으로 3KB는 낭비된다.
* 세그먼테이션 기법을 사용하면 메모리가 할당되고 해제되는 작업이 반복될 때 중간에 생긴 사용하지 않는 메모리가 쌓여 가용 메모리는 충분하지만 원하는 크기의 연속된 메모리를 할당할 수 없는 외부 단편화가 생긴다.
    * 예를 들어 6KB 메모리에 0~1KB, 2~3KB, 4~5KB 영역이 할당되어 있는데, 연속된 2KB 메모리를 추가로 할당해야 한다면 가용 메모리(3KB)는 충분하지만 연속된 영역을 할당할 수 없다.
* 위와 같은 문제를 해결하기 위하여 세그먼트를 페이징 기법으로 나누는 Paged segmentation 기법을 사용한다.
* 물론, 이번 내용도 실제 구현과 일부 상이할 수 있다.
    * 프로세서에는 운영모드라는게 존재한다. 16비트 리얼 모드에서는 세그먼테이션 기법만 사용하고, 세그먼테이션을 거쳐 나온 주소가 바로 물리 주소가 된다. 32비트 보호 모드에서는 세그먼테이션을 거쳐 나온 선형 주소가 페이징을 사용한다면 페이징의 입력 값이 된다. 64비트 LONG 모드 혹은 IA-32e 모드에서는 세그먼테이션을 통한 메모리 지정이 의미를 잃는다. (세그먼트 디스크립터에 있는 값이 무시된다.) 따라서 64비트 시스템에서는 세그먼테이션을 사용하지 않거나 아주 한정적으로(메모리 보호 기능을 위해) 사용된다.
    * 실제 리눅스의 경우 ```struct page``` 구조체를 이용하여 페이지를 나타내며, 이론상 5단계의 주소 변환을 통해 페이징 기법을 적용하고 있다. (실제로는 3/4단계로 축소될 수 있다.) 메모리 관리를 위해 따로 세그먼테이션을 수행하지는 않으며, 프로그램의 메모리를 논리적인 세그먼트로 나누기만 한다. 세그먼트 셀렉터 레지스터는 다른 용도로 사용된다.

## 페이지 교체 알고리즘

* 페이징 기법을 사용하여 메모리를 관리할 때, 물리 메모리 페이지 프레임이 전부 할당되었다면 새로운 페이지를 할당하기 위해선 기존에 할당되어 있는 페이지 프레임을 해제하여 교체해야 한다. 이 때 교체 대상이 되는 페이지는 현재 쓰이지 않고 있으며 앞으로도 쓰이지 않을 페이지여야 한다. 하지만 어떤 컴퓨터는 어떤 페이지가 앞으로 쓰이지 않을지 정확히 알 수 없기 때문에 다음과 같은 알고리즘을 이용하여 페이지를 교체한다.
    * OPT : 앞으로 가장 오랫동안 사용하지 않을 페이지를 교체하는 기법이다. 가장 이상적인 방법이지만, 구현이 사실상 불가능하다.
    * FIFO : 가장 먼저 적재되어 가장 오래 있었던 페이지를 교체하는 기법이다.
    * LFU : 사용 빈도가 가장 적은 페이지를 교체하는 기법이다.
    * LRU : 최근에 가장 오랫동안 사용하지 않은 페이지를 교체하는 기법이다.
    * NUR : 페이지 사용 여부를 두 개의 비트를 이용해 확인하는 LRU를 근사하는 기법이다.
    * 실제로는 거의 LRU 기법만 사용된다. 리눅스 커널 또한 LRU 기법을 사용한다.
    * 하지만 실제로 물리 메모리가 전부 할당되어 페이지 교체가 주기적으로 일어난다면 문제가 있는 상태이다. (프로세스가 종료되어 사용하지 않는 메모리를 교체한 것이 아니라, 실행 중인 프로세스의 메모리가 물리 메모리 부족으로 swap out하는 경우를 말한다.) 이 경우 전체적인 시스템 성능이 굉장히 하락해서 정상적인 운영이 불가능하다. 따라서 해당 상황이 발생한다면 시스템에 필요한 메모리 크기를 잘못 산정한 것은 아닌지, 혹은 시스템에 메모리 누수가 생긴 것은 아닌지 확인해야 한다.

## 세마포어 뮤텍스 스핀락 차이점

* 세마포어와 뮤텍스 차이는 추후 추가 예정
* 세마포어나 뮤텍스의 경우 일반적으로 락을 획득하지 못하게 되면 컨텍스트 스위칭을 수행한다. 반면에 스핀락은 락을 획득하지 못해도 계속 자원을 소모하며 busy-waiting을 수행한다.

## 스핀락을 사용하는 이유

* 싱글코어 환경에서 동기화 목적으로 인터럽트를 비활성화 해야 하는 경우들이 있다. 그런데 멀티코어 환경으로 넘어가면 인터럽트 비활성화는 코어 별로 작동하므로, 별도의 락 메커니즘을 사용해야 한다. 이 때 락 메커니즘으로 뮤텍스나 세마포어를 사용하게 되면 인터럽트 비활성화가 불가능하다. 따라서 인터럽트를 비활성화하면서 정상적으로 락을 걸기 위하여 스핀락을 사용해야 한다. 이 스핀락의 경우는 다른 락 메커니즘에 비해 자원을 많이 소모하기 때문에 꼭 필요한 상황에서 사용해야 한다.

## 데드락의 발생 조건

* Mutual Exclusion (상호 배제) : 프로세스들이 필요로 하는 자원에 대해 배타적인 통제권을 요구한다.
* Hold and Wait (점유 대기) : 프로세스가 할당된 자원을 가진 상태에서 다른 자원을 기다린다.
* No Preemption (비선점) : 프로세스가 어떤 자원의 사용을 끝낼 때까지 그 자원을 뺏을 수 없다.
* Circular Wait (순환 대기) : 각 프로세스는 순환적으로 다음 프로세스가 요구하는 자원을 가지고 있다.
* 데드락은 위 네 가지 조건을 만족하면 발생한다.
* 여기서 No Preemption은 Non-preemptive 스케줄링 방식을 뜻하는 것이 아니라, 락 메커니즘 자체가 선점 불가능한 경우를 뜻한다.

## C언어의 strtok 함수를 멀티쓰레드 환경에서 사용하면 안 되는 이유

* strtok 함수는 내부적으로 정적 변수를 사용한다. 여러 쓰레드에서 전역 변수/정적 변수에 동시에 접근하게 되면 Race Condition 문제가 발생한다. 이와 비슷한 문제를 갖는 함수로는, gethostbyname, ctime, rand, srand, 등의 함수가 있다.
* 여러 쓰레드 등에서 병렬 실행을 보장하도록 작성된 함수를 재진입성(Reentrancy)을 만족하는 함수라고 한다. strtok이나 rand 함수의 재진입성 만족 함수는 strtok_r, rand_r 같은 함수가 있다. 그리고 이 재진입성이라는 용어는 SUSv4에서 Thread-safety라는 용어에 흡수되었다.

## IPC 종류와 특징

* 대표적인 IPC로 파이프, Named 파이프 (FIFO), 공유 메모리, 메시지 큐가 있습니다.
* 일반 파이프는 한쪽 방향으로만 통신이 가능하고, 부모-자식과 같이 서로 연관된 프로세스끼리만 통신이 가능하다.
* Named 파이프는 다른부분은 파이프와 같고 서로 무관한 프로세스 끼리도 통신이 가능하다.
* 메시지 큐는 다수의 프로세스가 메시지를 전달할 수 있게 하는 IPC이다.
* 공유 메모리는 서로 다른 프로세스가 공통된 메모리 공간을 사용할 수 있도록 OS에서 만들어둔 공간을 이용한다.
* 소켓은 서로 다른 호스트들의 통신을 위한 인터페이스로 일종의 IPC이다.
* 실제 로우레벨 시스템 개발 시에 주로 사용되는 IPC 기법은 mmap과 DBUS이다.

## fork와 vfork의 차이점

* ```fork()```는 UNIX 계열에서 새로운 프로세스를 만드는 전통의 함수이다. 새로운 프로세스를 생성할 때, 자식 프로세스가 부모 프로세스를 복제하는 방식으로 생성된다.
* ```fork()```를 사용하는 패턴은 크게 두 가지가 있다. 하나는 멀티 프로세스로 동작하는 어플리케이션을 만드는 경우이고, 하나는 ```fork()``` 후에 다른 프로세스를 실행하는 경우이다. 쉘이나 바탕화면 등에서 프로그램을 새로 시작하는 경우는 전부 후자에 해당하며, 이러한 과정을 fork-exec이라고 부른다.
* ```fork()``` 이후에 바로 ```exec()``` 함수로 새로운 프로세스 이미지 교체 작업이 일어나면, 기존에 부모 프로세스로부터 내용을 복사하는 작업은 무의미한 작업이 된다. 이러한 오버헤드를 피하기 위하여 부모 프로세스의 메모리를 복제하지 않는 ```vfork()``` 함수가 생겼다. ```vfork()``` 함수는 부모 프로세스와 자식 프로세스가 페이지 테이블을 공유하도록 설계된 함수이다.
* 이런 ```vfork()``` 함수로 프로세스를 생성한 후, 자식 프로세스가 ```exec()```을 하기 전에 부모 혹은 자식 프로세스가 다른 작업을 해서 메모리 내용이 변경되면 예측할 수 없는 문제가 발생하였다. 심지어 ```fork()``` 작업 이 후 부모와 자식 프로세스 중 어떤 프로세스가 먼저 실행될지는 정해져있지 않기 때문에 (실제로 이는 OS별/버전별로 다르다) 결과를 예측할 수도 없었다. 이러한 문제들로 인해 표준에서 채택될수조차 없었다.
* 여기에 더해 추후 ```fork()``` 함수에 Copy On Write 기법이 탑재되어, 메모리 복제를 실제 Write 작업이 일어날 때로 미룸으로써 fork-exec 과정에서 무의미한 복제도 일어나지 않게 되었다. 하지만, fork-exec은 성능 외에도 파일 등의 상속 문제가 남아 있었기에 이를 대체하는 ```posix_spawn()``` 함수가 등장하였다. ```posix_spawn()``` 함수는 ```fork()```와 ```exec()``` 과정을 하나의 함수에서 수행하여 위 언급한 문제들을 해결하였다.

## 시나리오 문제

* A1. 100 - 쓰레드는 쓰레드 리더(쓰레드를 만든 프로세스)의 파일 디스크립터 테이블을 공유하므로 같은 시스템 파일 테이블에 접근하게 된다.
* A2. 100 - fork로 자식 프로세스를 생성했을 때 기존에 열려있던 파일 디스크립터 내용을 물려받게 된다. 부모 프로세스와 자식 프로세스의 파일 포인터가 같은 시스템 파일 테이블을 가리키므로 오프셋도 공유된다.
* A3. 0 - 이 후에 새로 열게되는 파일에 대해서는 서로 다른 시스템 파일 테이블을 가리키게 되므로 오프셋을 공유하지 않는다.
* 개념적으로는 각 프로세스마다 파일 디스크립터 테이블 항목이 있고, 파일 디스크립터 테이블에는 파일 포인터와 파일 디스크립터가 매핑되어 있다. 파일 디스크립터 테이블의 파일 포인터는 시스템의 파일 테이블을 가리킨다. 이 시스템 파일 테이블에는 파일 상태 플래그, 파일 오프셋, v-node 포인터 등이 있다. 그리고 v-node 포인터가 시스템의 v-node 테이블을 가리키고 v-node 테이블로부터 i-node 정보를 찾아갈 수 있다. i-node에는 파일의 크기, 위치, 링크 수, 소유자, 시간 등의 메타데이터가 존재한다.
    * 해당 내용은 실제 구현상 조금씩 달라질 수 있다. 예를 들어 리눅스의 경우, v-node가 없이 바로 i-node를 갖는다. 시스템 파일 테이블이란 것이 존재하긴 하지만, 프로세스의 파일 디스크립터 테이블에 있는 파일 포인터가 테이블을 가리키지는 않는다.
    * 즉, 리눅스 구현 상으로 프로세스/쓰레드(```struct task_struct```)는 파일 디스크립터 테이블(```struct files_struct```)을 갖고있다. 이 파일 디스크립터 테이블은 커널에서 관리하는 시스템 파일 구조체(```struct file```)을 가리킨다. 파일 구조체(```struct file```)은 실제 파일의 메타데이터를 관리하기 위한 i-node(```struct inode```)를 가리킨다. 또한, 파일 구조체(```struct file```)에 파일 플래그, 파일 소유자, 오프셋 등의 정보가 저장된다.
    * FreeBSD의 경우 위 개념과 실제 구현이 거의 일치한다.
* 한 프로세스 내에서 dup 시스템 콜을 통해 파일 디스크립터를 복사할 수 있다. 이 경우 같은 시스템 파일 테이블 항목을 가리키는 두 개의 파일 디스크립터가 생긴다.
* 한 프로세스가 fork를 하면 기존 프로세스 파일 디스크립터 테이블 내용을 물려받는다. 즉, 기존에 열려있던 부모 프로세스의 fd 3 파일 포인터와 자식 프로세스의 fd 3 파일 포인터가 같은 시스템 파일 테이블을 가리킨다.
* 이 후 새로 open하는 fd 4번부터는 서로 별개의 시스템 파일 테이블을 가리킨다.